{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "7c784dad58b1c097"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T00:15:08.021645Z",
     "start_time": "2025-03-21T00:15:05.258698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import Chroma vector store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "# Import the base Embeddings class from LangChain\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_chroma import Chroma\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Local GRC Files",
   "id": "436f2a87a85cc2d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:15:08.115948Z",
     "start_time": "2025-03-21T00:15:08.034647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.parsers import PyPDFParser\n",
    "from pathlib import Path\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "data_path = Path(\"../../data/test-pdfs\")\n",
    "\n",
    "assert(data_path.is_dir())\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=data_path,\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    blob_parser=PyPDFParser(),\n",
    ")"
   ],
   "id": "d95505f05d371ba3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:15:14.130641Z",
     "start_time": "2025-03-21T00:15:12.889217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = loader.load()\n",
    "# print(docs)\n",
    "# print(docs[0].page_content)\n",
    "# print([f'Document {i}: \\n{doc.metadata}\\n\\n' for i,doc in enumerate(docs,0)])"
   ],
   "id": "405e9e27b15403b2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:15:28.177481Z",
     "start_time": "2025-03-21T00:15:14.164355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Initialize the embeddings using nomic-embed-text\n",
    "\n",
    "# embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Create the Chroma vector store from documents and embeddings\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "\n",
    "# Index chunks\n",
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ],
   "id": "cbe5e88866853af1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elijah\\anaconda3\\envs\\GRCResponder\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:22:43.953195Z",
     "start_time": "2025-03-12T20:22:43.939200Z"
    }
   },
   "cell_type": "code",
   "source": "print(document_ids)",
   "id": "60023199f53fb6d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['753e0ecb-aff4-4cb8-8c4a-3ac3a282507f', '3eee743d-c5f6-469e-9a4e-4367e6851c1c', 'aabf37c0-2617-48ea-930a-0956ece13a77', '3f7bd2d8-cdbf-485c-a536-52a80b8dff9d', '5ecb37dc-ff45-45c2-a272-469199c7d120', 'cd38bce0-9372-40ca-a06a-ae76a5fa21fb', '8bbc43c0-3056-4e26-8a99-5b0f01dac9df', 'b7f3d157-3d11-47b1-b46e-5b68ab13292d', 'b1084032-4c44-4a6f-bea1-d41f7aa9521c', '117cda5d-61c6-4d71-bc2f-1d6ffd114efa', '0c97a6ea-1b83-465a-9fd4-7da3d901941d', '4cf817cc-b93e-4734-a68d-62969d3e7c15', '26b31ce2-feae-4bb1-9fdf-9f27fd3954e6', '5004afbf-2d87-4ec0-8991-f9f3f86f1af9', 'db81be04-64cf-421b-add9-666bde1df50a', 'f2e9755a-3636-4e4e-9a7f-1dc1998e4d80', '809a5811-e4f0-422f-a012-f48d30f39235', '02b15c4b-e5e4-4d04-8f86-f698ae05c77e', '2f6318ef-5c89-4a6b-a87c-25949861431f', 'd7728dde-470a-4983-be40-a08e36e4badb', '3bda72bd-cf88-4e61-a33f-0d74614a6301', '52e47ea1-7e7a-476f-9983-e28e8b61b81b', 'ea7e11b2-5556-4d2f-8353-a4318fbd3b72', '062198a1-dceb-4533-baf5-a579b155c709', 'aa5a0d53-8bba-4192-a88f-2a532643cd19', 'b53b441b-eb58-4246-b420-1117ca0075c9', 'd2a01713-7781-4db6-8f92-ee61504a5bc6', 'dc7a59b4-e6a7-4248-a9b7-7bc5531df2d1', '23014e66-d65d-4032-bdfb-b64dc4eb7daf', '2241283c-f8d3-4cb2-ace0-6fc3336c44bc', '3da988a0-57d2-4190-87f4-4f6bca9edb54', 'f40f8211-3343-4657-93ad-2f313c229587', 'f84fb6d8-edf5-428f-97b4-05bb145bb0bb', '3c45418d-4397-49fe-97b8-53b7993c7f95', '764008d6-2510-4f90-8fb8-502ff33370cf', '3ef59a55-985c-4adb-8348-7a26c54bf52c', '4f718c67-2799-45ee-89fa-04061f109f21', '5c1b68e1-8bcf-47fb-884b-79735185f4a9', '7bd9b54a-cfaa-42b8-a0ec-5ef04b651eec', '7ba84707-aa1d-4a68-9341-2ebadbddb0f0', 'f1957cd3-2bdb-4cae-a260-39ba057f31de', '4f513703-d2ec-4500-9283-9ffba03f7545', '61af53a0-35cd-4afa-8df9-e7c1eb0deabd', '782955f8-f370-4643-b925-ea0af35fdfc0', '2485e467-ba80-4066-b5b2-4207e3a6078d', 'f4c154c3-55ae-4951-8d7b-1e0d0ab26867', 'b00cea01-3e16-4a51-ae7c-6a0bd3f472b8', '58b49ebf-7d85-49ea-a6f9-f06db40a2025', '6c4d0dde-9c1d-48cd-81de-3504c0d4f07d', '5ad70bd4-fcff-4134-a4be-e69011801e7f', '4434cc23-6df1-4b04-af50-76f2c7a2a577', '2d2815c6-e69f-4161-8147-7fdfe505d1b6', 'efd00781-b4ef-4538-99be-fc30288201f7', '211a029c-be87-48f9-96da-798b1d3a83df', 'f25cd262-e2de-4a45-8754-e3dcf70e6a38', 'f562e42e-4a18-47fc-b27d-2be0b4d0ece9', '45d96293-f71b-46fe-bdf7-175528858a08', '364a0f40-418c-4b9c-a767-1f12db0229b9', 'ea648990-bace-4633-8e83-897c4a2414b7', 'e5c676b1-9d9b-42a3-b481-be80704dafb8', '5cfe85dc-3295-4760-a2f9-5f509e16c3dc', '82f2a04b-9681-4806-829c-1ccddc6ceb2c', '19a12321-63b4-420e-8861-616a888db68c', '28632348-43ea-4e68-82b0-989ed3760d9a', '5c77a5c8-a11e-4bad-9339-e3b81c69f603', '98a9131a-191c-4b63-a110-0e8443b2051d', 'b0f0c93b-17ca-4b89-a71b-bb4f654d1d34', '58b6b875-75a7-4d1d-9fe3-b299a84b3250', 'b7bbe982-f41a-43a7-8330-c9f9c81e8ed8', '977e9a3f-d803-47a9-ae89-69163ecbca7e', 'd9aa62c5-4824-4463-bde8-8d250e51f0c4', '75df54d6-58de-4c6c-95a0-6d6555a6c8b7', 'cae9e4f4-5b85-429a-bb11-5ac2c38e90ed', '8b8f3f42-abc2-4f92-9eeb-892df94b60ef', 'fa83f78b-c75a-4dbb-a245-215d47cd4023', '3d4bde36-8748-47ae-abcc-dac40e306d67', '4097668c-d5fc-44b5-a0d0-8f2081515c73', 'ff3c4121-60f3-41e5-826a-e53b58f13139', '8b75efe7-6de5-410e-8a20-fe25907954c0', '01155fbe-4d2d-4a11-940f-ba51f7b23c73', '793564bf-cc07-4264-97f4-8a1bf83f81d5', '1c9deaf1-e991-480d-9189-7c4edf099007', 'ceee6c3f-cdff-4983-8563-870b110f9ac9', '4773bcd2-0fde-46e4-ae9f-c228ade1b3b3', 'ef35fe8c-1abc-4a1f-b5e1-0ea5c2eaec1f', 'b0751122-348d-4a8b-a0e0-6a33f7b1223a', 'f93ce34d-0af4-4884-a44c-1327cc7ce48f', 'c10376e9-d398-460f-9bf1-83298a8dfe3a', '58ba4d8f-d183-432e-838f-36190333c971', '2ac9d512-23a5-49cf-a01c-90ea36a8a4d4', '110af259-c77b-47ab-98ea-1459e3715e32', '5abbc292-fe14-4202-a197-7825deefd90d', '38d382fa-33fe-45f4-b36c-4f9fa6d45f00', '09b3c90c-ee63-48ef-a11c-066c2efea594', '92d16cf1-c8f9-4853-9888-1b2f225a22e5', '58f029f4-38fd-4d0a-94a5-ab0a128b5912', '868ce467-10e9-4079-93be-8047b71b28ed', '055e4e3c-d93e-4466-b348-2408d533ae43', '7311251c-0b63-4b41-b6a4-b943deda24fe', 'b5a33571-b7f0-49b5-aeab-d1e677cc0b3f', 'd756e179-fd9e-4e88-9616-a243567f2837', '219a9d73-f9a9-4d57-983d-1b751a225014', '2c80c949-a1d2-4319-b372-57b326b979dc', '3ce8f736-142e-46fa-879a-7aab1fbb8449', '7644dbd8-d8c1-47f0-ae93-6f0677f628ba', '18d8a573-bf1f-491e-aae5-6aa4b365971c', '60a60325-64a2-4c3d-a455-f2aed33e7448', '6b1d948d-5f70-4037-9c32-8b275f8f08e7', 'a1fd457d-85f9-4213-a41c-49f897c27f77', '3407d2af-921f-4ded-bdfd-5637dc6bebf1', 'bc3dc8ce-688a-4f00-b62a-941c8b0749c2', '40cb677f-4958-4cdd-801d-72de2bc545ac', '96fc1da6-c6fc-4cbd-8c79-92809457c302', '17b91f19-5c0f-4592-b136-4c2216c892d2', 'e87e396f-3e38-4341-b64d-285071147067', '144063d8-91d7-4eb7-a7ca-1af2abaa2375', '44196ab9-e181-4272-9869-36b67ae2065b', 'd7ebffb0-92d0-419b-8d3f-a8c7e32886a1', '63032e14-09bd-4992-bd1d-7b8be6e30688', '7c633426-9ff7-469b-a297-d9e114b3b675', '529b7c4b-f4dd-432c-853b-1ed70192ab21', '5d9391ff-e59a-47f1-8d44-6d3610bd6bc6', 'c318f1c9-2f61-4b9e-a834-ffbb42818f30', '818add8d-79bd-4bbf-a96f-2b7640674f07', '8a167af0-35c3-49bd-9260-d05000caa6e2', '89487da4-d61b-41b6-8a75-e7faa7682dd9', '3de77898-ae9b-4472-b069-a11ea92d491a', 'dfa43f10-d31b-4460-9860-86dae786bb01', 'bec8923b-66b3-438b-a016-9c74833553db', 'ecd54585-e654-40b0-b92d-4a7625e1cf6f', 'c9e93bae-77f7-4acd-ac62-0333d032c912', '7f52dae0-ef64-489c-b491-b0a22d30544a', 'deedf78e-c5bc-41ba-a8bc-41153b3b7bfa', '71acaf08-1213-4204-803b-0d7b0a4f2b48', '975414e4-0405-4980-9fa2-e1023f5ace8e', '759d4a0d-720d-4115-b5a8-7b288f4ca6af', 'b939215f-324e-415c-b909-8a431d84efc8', '9f3698d3-04f9-477f-b9e9-2d34ac1ca3d3', '3f3b3e7d-bdbb-47c4-836a-ad692ab4b42a', '752aa383-7ac9-49d3-91e9-9dd9f1dcb6cb', '4c817932-d2a1-4689-ac2d-cad5f742f415', '91bde031-d424-4d23-aba7-7f79fb241cc6', 'd9cd8294-4491-4cbb-b407-f5d727dce063', '1d546422-28a5-448e-9ad9-522ed01c8e47', '536b8691-d34e-41ab-8c71-d17b33009047', 'f32e4bc7-fafa-4942-a966-82b87049fa80', '4c91f704-a729-4333-9cf3-5583ef21dad0', 'b2c00a9d-c95a-437e-ac86-eeb205d664e1', '3f9c3276-b93a-4c16-97c9-842ee073f869', '34b9dcb3-ba64-4027-bdad-922787afba40', 'c4e069de-e94a-4d58-9f5c-7916a77965d3', 'f0b61c91-6297-45dc-a4a9-d0b95463c4a0', '1e02f590-5f93-4837-b34a-df27ea4787d3', 'a78cf556-71d0-49d5-9b39-ebc8bc5fce6b', '03d6e59f-ab04-4ca3-b29a-bfbf4c7d4cb9', '01e90ad2-5070-4620-8a84-406a7793ee74', '2482088c-6695-4944-9f7a-79b1f9c84bc5', 'd7cfe2d6-b182-42ab-845e-7d2f3e2eb846', '0a60cf91-2e1c-4f4c-94c1-c909975efe56', '5a6fe807-58fd-436a-bac6-187fbab7f1a7', '4532c640-169b-490e-8365-ed2c48deee3e', '4cd6faea-2cfc-4b75-86e3-935346832a47', '958d22a6-dd75-4449-a8eb-6fdb8ace997b', 'ce76bc09-c79e-4b31-b2f0-c503ca8f2044', '2f3b2bc8-ebfe-4b2b-88b2-fe4eb6a41c4e', 'c0ee527e-1d3a-4ca7-acbb-a6a327fc1517', '0a76d1ae-5ce3-4fb1-b370-d3a47e093ef3', '2f5fb3ca-916a-4281-8e38-3a95f0ab9d52', 'bbc6b017-7af6-487e-8ba6-880406486bcf', '6ed0aee1-e2e1-4fe8-a2aa-15f8955221d7', '77908126-02d3-4777-bf2a-073b8c0546ee', '2d7d7167-4b5f-4c32-9b1c-234840ca1ef6', '307c8255-58c9-4059-880f-d92c204b3e40', '68050a59-8ff1-4cf8-9ebc-c3f920ed66bb', '5c9c8c29-2306-4586-ad65-8febb0210649', '06d3ab12-6aae-4224-b0f7-dc83d4d3e046', '1529a470-9969-4ce7-987c-0b20f73c907c', 'de4b04c8-e2e0-44d2-9ea4-576c84b37084', 'c52af305-2051-4a6f-b992-cef24b6ba61f', 'c714bf6d-9018-41e3-82e7-0afffbf569c6', '1f676dd3-b1ae-44a3-8f64-c1d7267efb8f', '6391a7da-4f06-47ef-a580-0a53b1bddf09', '48877bb2-d95d-4c8e-a9d9-0c02d701fa40', '9e127eb6-a7b8-4495-b30a-94f8fedc3dad', '89b9d670-5a4e-4a4f-a64f-c81ef43fc7e1', 'c7556b64-a575-445d-8d63-684cc73113f0', '45d9b4be-5548-4850-9fc2-34d36a7d4494', '25b6e6ca-d1f7-4167-8a41-45817a0f08e6', 'bb7bd60a-5ddd-4815-8f0c-c2841b60fd27', '430818d4-6f7c-4b9e-95cd-603b1a87b240', '0417b4df-aaf1-4018-9919-20ac7bc1af6f', '76c79164-8a8a-4aed-a48e-a3c7c5de1897', '7069042a-45e8-4bd9-98e1-ffd9e297b456', '52f93975-4fcd-47bb-9673-63bccfebbcb7', '121dbdfa-651d-4544-9caa-88f1701c082e', 'b506a924-19ea-4002-9310-5735dc7e1a19', 'ade05937-00f7-4e1d-b7f3-bcac59d9348e', '0de7c021-bb83-438f-a6c8-eb512cc61b30', '961cde48-07c9-4ba8-888a-359902a50757', '10ced523-8a4f-49ee-ac6d-b48b6c861f60', 'ddaabc02-ad22-4e22-99a3-0ffc410a794f', 'db503bd6-3be8-4f20-9a9f-7690941c6b0c', '9dc5f263-05b4-431a-a907-853b1ca9bcad', '98a4d389-5156-452d-9433-c6b72681042f', '5c952935-8cc7-4d1a-aa8b-f602ba7431bc', '9cd40ba7-263e-4229-96c0-c65d03e58e64', 'ab23d4c4-2141-4f45-9e1c-b2b218d284d7', 'f20efe63-ec4a-494d-bcc4-08e81fd275cc', 'e6425860-5315-4139-9c83-ba68185db01c', '214dda4e-8585-413c-8be1-d292cbd02c2f', 'a559e460-2bd2-44af-8bf9-1a4b2883b544', '8453ec05-21a1-40b4-8668-e060dc45395e', 'a3687af4-ad66-4b94-a547-fb090ed8f38d', '4688f995-f1ae-4e64-982a-83bc09b1856e', '5153f3fe-7eb0-469d-b2d2-8b29ec440398', 'dab24482-c5e2-4519-b6d9-a98128e90a00', '28ff01b1-cf7e-4ce6-8030-8d92ec642dce', 'ff8595c5-f37b-48d4-b861-64c11eb5078e', 'a63dce45-f629-4f6c-a17e-c673b5f65952', 'c5e61822-4f4d-47ce-ba21-e3de47209e98', '0c3027ad-d63e-4816-a072-38601d492ac8', '0b8a01a0-511e-4408-b18b-07afcd1e30ff', '0b4b881c-cedc-4c12-b57f-7394df473e21', '35c5e38f-310f-4e20-902e-3a141744b677', '0b110d2b-5144-491c-a251-d16024bfc490', '4b1fb162-5f76-4631-832a-99dc1c6c4b79', 'a06f1104-5877-4e8d-9156-74c81466f7bb', '2971c6cd-711e-423a-bb39-b55487ce203f', '54108c9c-e75a-46f2-8160-657ae9c35824', 'b04a110c-3df6-425d-bc28-afa4d25d1868', '8b87e6be-445e-4b29-a13a-3e766bd7a87a', '51ff3af3-66fe-4f16-9370-268195411aa7', '043ab10f-41de-4682-8e59-6b768d4bb22e', 'e6359d8e-8c68-4933-8504-9ade6d178d55', 'f6b4601a-a398-456f-a99f-627a4fb1a4ed', '13d97098-d1c2-4866-97db-7f2b49435678']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load LLM",
   "id": "b7a36c27c3dd3d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:15:28.615717Z",
     "start_time": "2025-03-21T00:15:28.197990Z"
    }
   },
   "cell_type": "code",
   "source": "llm = init_chat_model(\"llama3.2:3b-instruct-q8_0\", model_provider=\"ollama\")",
   "id": "3b86a817cd58dc4c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG",
   "id": "74cec309744c8e4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:21:33.476411Z",
     "start_time": "2025-03-21T00:21:33.448496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ],
   "id": "6a75da943de7fc65",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:20:53.078575Z",
     "start_time": "2025-03-21T00:20:22.902401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "97f7297cb1fffd0f",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:21:51.453983Z",
     "start_time": "2025-03-21T00:21:36.927852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "show_tool_output = False\n",
    "\n",
    "while True:\n",
    "    input_message = input()\n",
    "    if input_message == \"exit\":\n",
    "        break\n",
    "\n",
    "    for step in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        if show_tool_output:\n",
    "            step[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            evnt = step[\"messages\"][-1]\n",
    "            if (type(evnt) == HumanMessage or type(evnt) == AIMessage) and evnt.content != '':\n",
    "                evnt.pretty_print()"
   ],
   "id": "d63e22c13a14283b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hello, how does RAG work?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I don't know the details of how RAG works based on the provided context, but I can tell you that RAG (Retrieval-Augmentation-Generation) is a research paradigm that aims to integrate retrieval, augmentation, and generation capabilities into language models. It appears to be a broader concept that encompasses various stages, including \"Retrieval\", \"Generation\", and \"Augmentation\".\n",
      "\n",
      "The text mentions that the paper compiles and categorizes foundational technical concepts related to RAG methodologies and applications, but it doesn't provide a detailed explanation of how RAG works.\n",
      "\n",
      "If you need more information on this topic, I suggest checking out additional sources or the original research paper that provides a comprehensive overview of RAG.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m show_tool_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 7\u001B[0m     input_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_message \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GRCResponder\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GRCResponder\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Show Context",
   "id": "4348a78598a8fd8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:33:23.695389Z",
     "start_time": "2025-03-21T00:33:23.668873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    global K\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=K)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"You are an expert on machine learning\"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    # prompt = conversation_messages\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ],
   "id": "6bfa96e058f25171",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:47:44.976745Z",
     "start_time": "2025-03-21T00:47:44.963731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "def main():\n",
    "    while True:\n",
    "        input_message = input()\n",
    "        if input_message == \"exit\":\n",
    "            break\n",
    "\n",
    "        for step in graph.stream(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "            stream_mode=\"values\",\n",
    "        ):\n",
    "            if show_tool_output:\n",
    "                step[\"messages\"][-1].pretty_print()\n",
    "            else:\n",
    "                evnt = step[\"messages\"][-1]\n",
    "                if (type(evnt) == HumanMessage or type(evnt) == AIMessage) and evnt.content != '':\n",
    "                    evnt.pretty_print()"
   ],
   "id": "6ef9fa9d985e083a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T01:15:01.106781Z",
     "start_time": "2025-03-21T01:14:51.058129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM Model: llama3.2:3b-instruct-q8_0\n",
    "# Embedding Model: all-MiniLM-L6-v2\n",
    "K = 5\n",
    "show_tool_output = True\n",
    "\n",
    "main()"
   ],
   "id": "676d5ebeffcc574d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is RAG?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (f218aa38-1c6a-4c72-8b60-2201ac2cd910)\n",
      " Call ID: f218aa38-1c6a-4c72-8b60-2201ac2cd910\n",
      "  Args:\n",
      "    query: RAG\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'author': '', 'creationdate': '2024-03-28T00:54:45+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'page': 0, 'page_label': '1', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\data\\\\test-pdfs\\\\2312.10997v5.pdf', 'subject': '', 'title': '', 'total_pages': 21, 'trapped': '/False'}\n",
      "Content: could clarify its broader trajectory. This survey endeavors to\n",
      "fill this gap by mapping out the RAG process and charting\n",
      "its evolution and anticipated future paths, with a focus on the\n",
      "integration of RAG within LLMs. This paper considers both\n",
      "technical paradigms and research methods, summarizing three\n",
      "main research paradigms from over 100 RAG studies, and\n",
      "analyzing key technologies in the core stages of “Retrieval,”\n",
      "“Generation,” and “Augmentation.” On the other hand, current\n",
      "research tends to focus more on methods, lacking analysis and\n",
      "summarization of how to evaluate RAG. This paper compre-\n",
      "hensively reviews the downstream tasks, datasets, benchmarks,\n",
      "and evaluation methods applicable to RAG. Overall, this\n",
      "paper sets out to meticulously compile and categorize the\n",
      "foundational technical concepts, historical progression, and\n",
      "the spectrum of RAG methodologies and applications that\n",
      "have emerged post-LLMs. It is designed to equip readers and\n",
      "\n",
      "Source: {'author': '', 'creationdate': '2024-03-28T00:54:45+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'page': 13, 'page_label': '14', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\data\\\\test-pdfs\\\\2312.10997v5.pdf', 'subject': '', 'title': '', 'total_pages': 21, 'trapped': '/False'}\n",
      "Content: A series of benchmark tests and tools have been proposed\n",
      "to facilitate the evaluation of RAG.These instruments furnish\n",
      "quantitative metrics that not only gauge RAG model perfor-\n",
      "mance but also enhance comprehension of the model’s capabil-\n",
      "ities across various evaluation aspects. Prominent benchmarks\n",
      "such as RGB, RECALL and CRUD [167]–[169] focus on\n",
      "appraising the essential abilities of RAG models. Concur-\n",
      "rently, state-of-the-art automated tools like RAGAS [164],\n",
      "ARES [165], and TruLens 8 employ LLMs to adjudicate the\n",
      "quality scores. These tools and benchmarks collectively form\n",
      "a robust framework for the systematic evaluation of RAG\n",
      "models, as summarized in Table IV.\n",
      "VII. D ISCUSSION AND FUTURE PROSPECTS\n",
      "Despite the considerable progress in RAG technology, sev-\n",
      "eral challenges persist that warrant in-depth research.This\n",
      "chapter will mainly introduce the current challenges and future\n",
      "research directions faced by RAG.\n",
      "A. RAG vs Long Context\n",
      "\n",
      "Source: {'author': '', 'creationdate': '2024-03-28T00:54:45+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\data\\\\test-pdfs\\\\2312.10997v5.pdf', 'subject': '', 'title': '', 'total_pages': 21, 'trapped': '/False'}\n",
      "Content: to the user’s query. These articles, combined with the original\n",
      "question, form a comprehensive prompt that empowers LLMs\n",
      "to generate a well-informed answer.\n",
      "The RAG research paradigm is continuously evolving, and\n",
      "we categorize it into three stages: Naive RAG, Advanced\n",
      "RAG, and Modular RAG, as showed in Figure 3. Despite\n",
      "RAG method are cost-effective and surpass the performance\n",
      "of the native LLM, they also exhibit several limitations.\n",
      "The development of Advanced RAG and Modular RAG is\n",
      "a response to these specific shortcomings in Naive RAG.\n",
      "A. Naive RAG\n",
      "The Naive RAG research paradigm represents the earli-\n",
      "est methodology, which gained prominence shortly after the\n",
      "\n",
      "Source: {'author': '', 'creationdate': '2024-03-28T00:54:45+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'page': 0, 'page_label': '1', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\data\\\\test-pdfs\\\\2312.10997v5.pdf', 'subject': '', 'title': '', 'total_pages': 21, 'trapped': '/False'}\n",
      "Content: foundational technical concepts, historical progression, and\n",
      "the spectrum of RAG methodologies and applications that\n",
      "have emerged post-LLMs. It is designed to equip readers and\n",
      "professionals with a detailed and structured understanding of\n",
      "both large models and RAG. It aims to illuminate the evolution\n",
      "of retrieval augmentation techniques, assess the strengths and\n",
      "weaknesses of various approaches in their respective contexts,\n",
      "and speculate on upcoming trends and innovations.\n",
      "Our contributions are as follows:\n",
      "• In this survey, we present a thorough and systematic\n",
      "review of the state-of-the-art RAG methods, delineating\n",
      "its evolution through paradigms including naive RAG,\n",
      "arXiv:2312.10997v5  [cs.CL]  27 Mar 2024\n",
      "\n",
      "Source: {'author': '', 'creationdate': '2024-03-28T00:54:45+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'page': 1, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '..\\\\..\\\\data\\\\test-pdfs\\\\2312.10997v5.pdf', 'subject': '', 'title': '', 'total_pages': 21, 'trapped': '/False'}\n",
      "Content: 2\n",
      "Fig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,\n",
      "research on RAG initially focused on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the inference stage. Subsequent\n",
      "research has delved deeper, gradually integrating more with the fine-tuning of LLMs. Researchers have also been exploring ways to enhance language models\n",
      "in the pre-training stage through retrieval-augmented techniques.\n",
      "advanced RAG, and modular RAG. This review contex-\n",
      "tualizes the broader scope of RAG research within the\n",
      "landscape of LLMs.\n",
      "• We identify and discuss the central technologies integral\n",
      "to the RAG process, specifically focusing on the aspects\n",
      "of “Retrieval”, “Generation” and “Augmentation”, and\n",
      "delve into their synergies, elucidating how these com-\n",
      "ponents intricately collaborate to form a cohesive and\n",
      "effective RAG framework.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "RAG stands for Retrieval-Augmentation Generation, which refers to a research paradigm in the field of natural language processing (NLP). It involves using retrieval-based techniques to augment or enhance the capabilities of large language models (LLMs) in generating human-like responses. The goal of RAG is to improve the performance and effectiveness of LLMs by leveraging additional information from external sources during the generation process.\n",
      "\n",
      "In the context of RAG, researchers have identified three stages: Naive RAG, Advanced RAG, and Modular RAG. Each stage represents a progression in the development of RAG methods, with the goal of addressing specific limitations and shortcomings in earlier approaches.\n",
      "\n",
      "RAG research has evolved over time, initially focusing on leveraging the powerful contextual learning abilities of LLMs primarily for inference. However, subsequent research has delved deeper into integrating retrieval-augmented techniques during fine-tuning and pre-training stages, ultimately leading to more effective and cohesive RAG frameworks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m K \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m      4\u001B[0m show_tool_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[42], line 5\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmain\u001B[39m():\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 5\u001B[0m         input_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m input_message \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m      7\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GRCResponder\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GRCResponder\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d186ea41f827ba6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
